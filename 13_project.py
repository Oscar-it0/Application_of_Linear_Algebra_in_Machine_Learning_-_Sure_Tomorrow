#!/usr/bin/env python
# coding: utf-8

# # ¬°Hola Oscar! üòä
# 
# Mi nombre es **Alejandro Castellanos** y hoy tengo el placer de ser el revisor de tu proyecto.
# 
# Voy a revisar todo tu c√≥digo con detalle, buscando tanto los puntos fuertes como aquellos en los que podr√≠as mejorar. Te dejar√© comentarios a lo largo del notebook, destacando lo que has hecho bien y sugiriendo ajustes donde sea necesario. Si encuentro alg√∫n error, no te preocupes, te lo har√© saber de forma clara y te dar√© informaci√≥n √∫til para que puedas corregirlo en la pr√≥xima iteraci√≥n. Si en alg√∫n punto tienes comentarios, si√©ntete libre de dejarlos tambi√©n.
# 
# 
# Encontrar√°s mis comentarios espec√≠ficos dentro de cajas verdes, amarillas o rojas, es muy importante que no muevas, modifiques o borres mis comentarios, con el fin de tener un seguimiento adecuado de tu proceso:
# 
# 
# <div class="alert alert-block alert-success">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si todo est√° perfecto.
# </div>
# 
# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.
# </div>
# 
# <div class="alert alert-block alert-danger">
# <b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>
# Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.
# </div>
# 
# Puedes responderme de esta forma:
# <div class="alert alert-block alert-info">
# <b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>
# </div>
# 
# A continuaci√≥n te dejar√© un comentario general con mi valoraci√≥n del proyecto. **¬°Mi objetivo es que sigas aprendiendo y mejorando con cada paso!**

# ----

# <div class="alert alert-block alert-success">
# <b>Comentario General del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Oscar, hiciste un trabajo muy completo y bien estructurado. Destacaste el impacto del escalado en kNN, aplicaste correctamente m√©tricas como RMSE, R¬≤ y F1, y comparaste modelos de forma efectiva. Adem√°s, lograste una transformaci√≥n algebraica s√≥lida para evaluar datos ofuscados. ¬°Excelente!
# 
# ¬°Contin√∫a por este camino y te deseo mucho √©xito en tu pr√≥ximo Sprint! üöÄ
#  
# *Estado del Proyecto*: **Aprobado**
# 
# </div>

# ----

# Comentario inicial.
# 
# Por favor considerar que los comentarios por secci√≥n se encuentran al final de cada una de las
# secciones.

# # Descripci√≥n

# La compa√±√≠a de seguros Sure Tomorrow quiere resolver varias tareas con la ayuda de machine learning y te pide que eval√∫es esa posibilidad.
# - Tarea 1: encontrar clientes que sean similares a un cliente determinado. Esto ayudar√° a los agentes de la compa√±√≠a con el marketing.
# - Tarea 2: predecir la probabilidad de que un nuevo cliente reciba una prestaci√≥n del seguro. ¬øPuede un modelo de predictivo funcionar mejor que un modelo dummy?
# - Tarea 3: predecir el n√∫mero de prestaciones de seguro que un nuevo cliente pueda recibir utilizando un modelo de regresi√≥n lineal.
# - Tarea 4: proteger los datos personales de los clientes sin afectar al modelo del ejercicio anterior. Es necesario desarrollar un algoritmo de transformaci√≥n de datos que dificulte la recuperaci√≥n de la informaci√≥n personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento u ofuscaci√≥n de datos. Pero los datos deben protegerse de tal manera que no se vea afectada la calidad de los modelos de machine learning. No es necesario elegir el mejor modelo, basta con demostrar que el algoritmo funciona correctamente.
# 

# # Preprocesamiento y exploraci√≥n de datos
# 
# ## Inicializaci√≥n

# In[1]:


pip install scikit-learn --upgrade


# In[2]:


# Importaci√≥n de librer√≠as

import numpy as np
import pandas as pd

import seaborn as sns

import sklearn.linear_model
import sklearn.metrics
from sklearn.metrics import r2_score
import sklearn.neighbors
from sklearn.neighbors import NearestNeighbors
from sklearn.neighbors import KNeighborsClassifier
import sklearn.preprocessing

import math
from sklearn.model_selection import train_test_split

from IPython.display import display


# ---------------

# ## Carga de datos

# Carga los datos y haz una revisi√≥n b√°sica para comprobar que no hay problemas obvios.

# In[3]:


# Importaci√≥n de DF

df = pd.read_csv('/datasets/insurance_us.csv')


# Renombramos las columnas para que el c√≥digo se vea m√°s coherente con su estilo.

# In[4]:


df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})


# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Buen trabajo has renombrado las columnas para que sean m√°s consistentes y manejables, lo cual es una buena pr√°ctica para evitar errores en el manejo de datos.
# 
# 
# 
# </div>

# In[5]:


df.sample(10)


# In[6]:


df.info()


# In[7]:


# puede que queramos cambiar el tipo de edad (de float a int) aunque esto no es crucial

# escribe tu conversi√≥n aqu√≠ si lo deseas:

df['age'] = df['age'].astype('int64')


# In[8]:


# comprueba que la conversi√≥n se haya realizado con √©xito

df.info()


# In[9]:


# ahora echa un vistazo a las estad√≠sticas descriptivas de los datos.# ¬øSe ve todo bien?


# In[10]:


# Revisi√≥n de filas duplicadas en dataframes
print("Filas duplicadas en df: ",df.index.duplicated().sum())


# In[11]:


# Forma de los dataframes
print("Filas y columnas en df: ",df.shape)


# In[12]:


# Verificar si hay valores NaN

hay_nan = df.isnull().any().any()
if hay_nan == True:
    print("El DataFrame contiene valores ausentes")
else:
    print("El DataFrame NO contiene valores ausentes")

# Verificar si hay valores inf
df_inf = np.isinf(df)
if df_inf.any().any():
    print("El DataFrame contiene valores infinitos")
else:
    print("El DataFrame NO contiene valores infinitos")


# In[13]:


# Descripci√≥n de datos

df.describe()


# In[14]:


sns.boxplot(data = df)


# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Muy buen trabajo usando funciones como `info`, `describe` y `sample`, esto te permite hacer una primera revisi√≥n de los datos, su estructura y contenido. 
#     
# Adem√°s hiciste una comprobaci√≥n de datos faltantes, lo cual es clave para evitar errores o sesgos en el an√°lisis de los dato
# 
# </div>

# -----------------------

# ## An√°lisis exploratorio de datos

# Vamos a comprobar r√°pidamente si existen determinados grupos de clientes observando el gr√°fico de pares.

# In[15]:


g = sns.pairplot(df, kind='hist')
g.fig.set_size_inches(12, 12)


# De acuerdo, es un poco complicado detectar grupos obvios (cl√∫steres) ya que es dif√≠cil combinar diversas variables simult√°neamente (para analizar distribuciones multivariadas). Ah√≠ es donde LA y ML pueden ser bastante √∫tiles.

# Comentarios Preprocesamiento y exploraci√≥n de datos.
# 
# * Importaci√≥n de librer√≠as
# * Importaci√≥n de DF
#     * Renombramiento de columnas
#     * Conversi√≥n de tipo de datos
#     * Revisi√≥n de filas duplicadas
#     * Verificaci√≥n de valores ausentes e infinitos
#     * Descripci√≥n de datos
#     * Distribuci√≥n de datos: Se observa que la magnitud de la columna "income" puede afectar en el desempe√±o del modelo.

# <div class="alert alert-block alert-warning">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Has creado correctamente el *pair-plot*. Es muy importante que este tipo de informaci√≥n la analises e interpretes para que no se queden como datos sin contexto. Por ejemplo, podemos ver que *age* tiene una distribuci√≥n sesgada a la derecha, lo que indica que hay m√°s personas j√≥venes que mayores, mientras que *insurance_benefits* presenta una distribuci√≥n concentrada en valores bajos (0 o 1 predominante).
# 
# </div>

# ------------------

# # Tarea 1. Clientes similares

# En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos m√°s cercanos (objetos) para un objeto dado bas√°ndose en la distancia entre los objetos.
# 
# Es posible que quieras revisar las siguientes lecciones (cap√≠tulo -> lecci√≥n)
# 
# - Distancia entre vectores -> Distancia euclidiana
# - Distancia entre vectores -> Distancia Manhattan
# 
# Para resolver la tarea, podemos probar diferentes m√©tricas de distancia.

# Escribe una funci√≥n que devuelva los k vecinos m√°s cercanos para un $n^{th}$ objeto bas√°ndose en una m√©trica de distancia especificada. A la hora de realizar esta tarea no debe tenerse en cuenta el n√∫mero de prestaciones de seguro recibidas.
# 
# Puedes utilizar una implementaci√≥n ya existente del algoritmo kNN de scikit-learn (consulta [el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) o tu propia implementaci√≥n.
# 
# Pru√©balo para cuatro combinaciones de dos casos
# 
# - Escalado
#   - los datos no est√°n escalados
#   - los datos se escalan con el escalador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)
# - M√©tricas de distancia
#   - Euclidiana
#   - Manhattan
# 
# Responde a estas preguntas:
# - ¬øEl hecho de que los datos no est√©n escalados afecta al algoritmo kNN? Si es as√≠, ¬øc√≥mo se manifiesta?
# - ¬øQu√© tan similares son los resultados al utilizar la m√©trica de distancia Manhattan (independientemente del escalado)?

# In[16]:


feature_names = ['gender', 'age', 'income', 'family_members']


# In[17]:


def get_knn(df, n, k, metric):
    
    """
    Devuelve los k vecinos m√°s cercanos

    :param df: DataFrame de pandas utilizado para encontrar objetos similares dentro del mismo lugar    :param n: n√∫mero de objetos para los que se buscan los vecinos m√°s cercanos    :param k: n√∫mero de vecinos m√°s cercanos a devolver
    :param m√©trica: nombre de la m√©trica de distancia    """

    nbrs = NearestNeighbors(n_neighbors=k, metric=metric).fit(df[feature_names])
    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)
    
    df_res = pd.concat([
        df.iloc[nbrs_indices[0]], 
        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])
        ], axis=1)
    
    return df_res


# In[18]:


knn_test_e = get_knn(df, 2, 4, 'euclidean')
knn_test_e


# In[19]:


knn_test_m = get_knn(df, 2, 4, 'cityblock')
knn_test_m


# Escalar datos.

# In[20]:


feature_names = ['gender', 'age', 'income', 'family_members']

transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())

df_scaled = df.copy()
df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())


# In[21]:


df_scaled.sample(5)


# Ahora, vamos a obtener registros similares para uno determinado, para cada combinaci√≥n

# In[22]:


knn_test_scld_e = get_knn(df_scaled, 2, 4, 'euclidean')
knn_test_scld_e


# In[23]:


knn_test_scld_m = get_knn(df_scaled, 2, 4, 'cityblock')
knn_test_scld_m


# Comentarios Tarea 1.
# 
# * Definici√≥n y aplicaci√≥n de funciones:
#     * get_knn
#    
# * Escalamiento de datos con MaxAbsScaler

# Respuestas a las preguntas

# **¬øEl hecho de que los datos no est√©n escalados afecta al algoritmo kNN? Si es as√≠, ¬øc√≥mo se manifiesta?** 
# 
# * Las distancias obtenidas utilizando los datos originales para los 4 vecinos cambian segun los tipos de distancia "Euclidiana" y "Manhattan", sin embargo los vecinos son los mismos. Sin embargo al utilizar datos escalados los vecinos cambian, as√≠ tambi√©n las distancias seg√∫n los dos tipos evaluados.

# **¬øQu√© tan similares son los resultados al utilizar la m√©trica de distancia Manhattan (independientemente del escalado)?** 
# 
# * Son similares, sin embargo la distancia Euclidiana es por poco menor en los casos analizados.

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Has hecho un buen trabajo identificando c√≥mo el escalado de datos influye en los resultados del algoritmo kNN, especialmente al observar el cambio en los vecinos seleccionados al aplicar MaxAbsScaler. Tambi√©n es acertado c√≥mo reconoces las diferencias sutiles entre las m√©tricas de distancia evaluadas, destacando que, aunque los resultados son similares, la m√©trica Euclidiana tiende a producir distancias ligeramente menores.
# 
# </div>

# ------------------

# # Tarea 2. ¬øEs probable que el cliente reciba una prestaci√≥n del seguro?

# En t√©rminos de machine learning podemos considerarlo como una tarea de clasificaci√≥n binaria.

# Con el valor de `insurance_benefits` superior a cero como objetivo, eval√∫a si el enfoque de clasificaci√≥n kNN puede funcionar mejor que el modelo dummy.
# 
# Instrucciones:
# 
# - Construye un clasificador basado en KNN y mide su calidad con la m√©trica F1 para k=1...10 tanto para los datos originales como para los escalados. Ser√≠a interesante observar c√≥mo k puede influir en la m√©trica de evaluaci√≥n y si el escalado de los datos provoca alguna diferencia. Puedes utilizar una implementaci√≥n ya existente del algoritmo de clasificaci√≥n kNN de scikit-learn (consulta [el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) o tu propia implementaci√≥n.
# - Construye un modelo dummy que, en este caso, es simplemente un modelo aleatorio. Deber√≠a devolver "1" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestaci√≥n del seguro, 0.5, 1.
# 
# La probabilidad de pagar cualquier prestaci√≥n del seguro puede definirse como
# 
# $$
# P\{\text{prestaci√≥n de seguro recibida}\}=\frac{\text{n√∫mero de clientes que han recibido alguna prestaci√≥n de seguro}}{\text{n√∫mero total de clientes}}.
# $$
# 
# Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporci√≥n 70:30.

# In[24]:


# —Åalcula el objetivo
df['insurance_benefits_received'] = df['insurance_benefits']>0
df['insurance_benefits_received'] = df['insurance_benefits_received'] * 1
df

# —Åalcula el objetivo scaled
df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits']>0
df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits_received'] * 1
df_scaled


# In[25]:


# comprueba el desequilibrio de clases con value_counts()

ibr = df['insurance_benefits_received'].value_counts()
ibr


# In[26]:


sns.barplot(df['insurance_benefits_received'], df['insurance_benefits_received'].value_counts(), y=df['insurance_benefits_received'])


# In[27]:


def get_knn_class(data, neighbors):
    features = data.drop(['insurance_benefits','insurance_benefits_received'], axis=1) # extrae las caracter√≠sticas
    target = data['insurance_benefits_received'] # extrae los objetivos
    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=12345)
    
    f1_scr = []
    for k in range(1,neighbors):
        knn_model = KNeighborsClassifier(n_neighbors=k)
        knn_model.fit(features_train, target_train)
        knn_predict = knn_model.predict(features_test)
    
        f1_score = sklearn.metrics.f1_score(target_test, knn_predict)
        f1_scr.append(f1_score)
        
    return f1_scr


# In[28]:


get_knn_clss_f1 = get_knn_class(df, 11)
get_knn_clss_f1


# In[29]:


get_knn_clss_f1 = get_knn_class(df_scaled, 11)
get_knn_clss_f1


# In[30]:


def eval_classifier(y_true, y_pred):
    
    f1_score = sklearn.metrics.f1_score(y_true, y_pred)
    print(f'F1: {f1_score:.2f}')
    
# si tienes alg√∫n problema con la siguiente l√≠nea, reinicia el kernel y ejecuta el cuaderno de nuevo    
    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')
    print('Matriz de confusi√≥n')
    print(cm)


# In[31]:


# generar la salida de un modelo aleatorio

def rnd_model_predict(P, size, seed=42):

    rng = np.random.default_rng(seed=seed)
    return rng.binomial(n=1, p=P, size=size)


# In[32]:


# Probabilidades del modelo

for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:

    print(f'La probabilidad: {P:.2f}')
    y_pred_rnd = rnd_model_predict(P, df['insurance_benefits_received'].shape[0], seed=42)
        
    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)
    
    print()


# Comentarios Tarea 2.
# 
# * C√°lculo del objetivo (en datos originales y escalados)
# 
# * Presentaci√≥n del desequilibrio de clases
# 
# * Definici√≥n y aplicaci√≥n de funciones:
#     * get_knn_class: Las evaluaciones F1 para los datos escalados son por mucho mejores que las de los datos originales.
#     * eval_classifier
#     * rnd_model_predict
#     
# * Probabilidades del modelo
# 

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Destacas de manera clara c√≥mo el escalado de los datos influye significativamente en el desempe√±o del clasificador, mostrando mejoras notables en la m√©trica F1. Tambi√©n se aprecia tu atenci√≥n al desequilibrio de clases, un aspecto crucial en problemas de clasificaci√≥n que puede afectar fuertemente los resultados y su interpretaci√≥n. La aplicaci√≥n de funciones personalizadas aporta valor al an√°lisis, permitiendo una evaluaci√≥n m√°s precisa del modelo.
# 
# </div>

# -----------------

# # Tarea 3. Regresi√≥n (con regresi√≥n lineal)

# Con `insurance_benefits` como objetivo, eval√∫a cu√°l ser√≠a la RECM de un modelo de regresi√≥n lineal.

# Construye tu propia implementaci√≥n de regresi√≥n lineal. Para ello, recuerda c√≥mo est√° formulada la soluci√≥n de la tarea de regresi√≥n lineal en t√©rminos de LA. Comprueba la RECM tanto para los datos originales como para los escalados. ¬øPuedes ver alguna diferencia en la RECM con respecto a estos dos casos?
# 
# Denotemos
# 
# - $X$: matriz de caracter√≠sticas; cada fila es un caso, cada columna es una caracter√≠stica, la primera columna est√° formada por unidades
# - $y$ ‚Äî objetivo (un vector)
# - $\hat{y}$ ‚Äî objetivo estimado (un vector)
# - $w$ ‚Äî vector de pesos
# 
# La tarea de regresi√≥n lineal en el lenguaje de las matrices puede formularse as√≠:
# 
# $$
# y = Xw
# $$
# 
# El objetivo de entrenamiento es entonces encontrar esa $w$ w que minimice la distancia L2 (ECM) entre $Xw$ y $y$:
# 
# $$
# \min_w d_2(Xw, y) \quad \text{or} \quad \min_w \text{MSE}(Xw, y)
# $$
# 
# Parece que hay una soluci√≥n anal√≠tica para lo anteriormente expuesto:
# 
# $$
# w = (X^T X)^{-1} X^T y
# $$
# 
# La f√≥rmula anterior puede servir para encontrar los pesos $w$ y estos √∫ltimos pueden utilizarse para calcular los valores predichos
# 
# $$
# \hat{y} = X_{val}w
# $$

# Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporci√≥n 70:30. Utiliza la m√©trica RECM para evaluar el modelo.

# In[33]:


class MyLinearRegression:
    
    def __init__(self):
        
        self.weights = None
    
    def fit(self, X, y):
        
        # a√±adir las unidades
        X2 = np.append(np.ones([len(X), 1]), X, axis=1)
        self.weights = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)
        self.w = self.weights[1:]
        self.w0 = self.weights[0]

    def predict(self, X):
        
        # a√±adir las unidades
        #X2 = # <tu c√≥digo aqu√≠>
        y_pred = X.dot(self.w) + self.w0
        
        return y_pred


# In[34]:


def eval_regressor(y_true, y_pred):
    
    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))
    print(f'RMSE: {rmse:.2f}')
    
    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))
    print(f'R2: {r2_score:.2f}')    


# In[35]:


# Resultados del modelo (pesos, RMSE y R2)

X = df[['gender', 'age', 'income', 'family_members']].to_numpy()
y = df['insurance_benefits'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

lr = MyLinearRegression()

lr.fit(X_train, y_train)
print("Pesos:")
print(lr.weights)

y_test_pred = lr.predict(X_test)
eval_regressor(y_test, y_test_pred)


# In[36]:


# Resultados del modelo con datos escalados (pesos, RMSE y R2)

X = df_scaled[['gender', 'age', 'income', 'family_members']].to_numpy()
y = df_scaled['insurance_benefits'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)

lr = MyLinearRegression()

lr.fit(X_train, y_train)
print("Pesos:")
print(lr.weights)

y_test_pred = lr.predict(X_test)
eval_regressor(y_test, y_test_pred)


# Comentarios Tarea 3.
# 
# * Creaci√≥n y aplicaci√≥n de clase:
#     * MyLinearRegression
#     
# * Definici√≥n y aplicaci√≥n de funciones:
#     * eval_regressor
#     
# * Resultados del modelo con datos originales y escalados (pesos, RMSE y R2)
# 
# ¬øPuedes ver alguna diferencia en la RECM con respecto a estos dos casos?
# 
# * Las m√©tricas de evaluaci√≥n son similares sin embargo los pesos se adaptan a sus magnitudes en ambos casos.

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (2da Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
#     
# Muy buen implementaci√≥n de las funciones para el modelo de regresi√≥n lineal. Se evidencia que este caso tiene una tendencia m√°s hacia ser un problema de clasificaci√≥n para `insurance_benefits`, ya que cuando realizamos el an√°lisis como una regresi√≥n el rendimiento de este modelo no es tan bueno como se puede observar con el **R2**
#     
# 
# </div>

# ---------------

# # Tarea 4. Ofuscar datos

# Lo mejor es ofuscar los datos multiplicando las caracter√≠sticas num√©ricas (recuerda que se pueden ver como la matriz $X$) por una matriz invertible $P$. 
# 
# $$
# X' = X \times P
# $$
# 
# Trata de hacerlo y comprueba c√≥mo quedar√°n los valores de las caracter√≠sticas despu√©s de la transformaci√≥n. Por cierto, la propiedad de invertibilidad es importante aqu√≠, as√≠ que aseg√∫rate de que $P$ sea realmente invertible.
# 
# Puedes revisar la lecci√≥n 'Matrices y operaciones matriciales -> Multiplicaci√≥n de matrices' para recordar la regla de multiplicaci√≥n de matrices y su implementaci√≥n con NumPy.

# In[37]:


# Determinaci√≥n de matriz
personal_info_column_list = ['gender', 'age', 'income', 'family_members']
df_pn = df[personal_info_column_list]


# In[38]:


X = df_pn.to_numpy()
X


# Generar una matriz aleatoria $P$.

# In[39]:


rng = np.random.default_rng(seed=42)
P = rng.random(size=(X.shape[1], X.shape[1]))
P


# Comprobar que la matriz P sea invertible

# In[40]:


P_inv = np.linalg.inv(P)
P_inv


# In[41]:


X_1 = np.dot(X, P)
X_1
len(X_1)


# ¬øPuedes adivinar la edad o los ingresos de los clientes despu√©s de la transformaci√≥n?

# No se pueden saber los datos ya que quedan afectados por operaciones con n√∫meros aleatorios.

# ¬øPuedes recuperar los datos originales de $X'$ si conoces $P$? Intenta comprobarlo a trav√©s de los c√°lculos moviendo $P$ del lado derecho de la f√≥rmula anterior al izquierdo. En este caso las reglas de la multiplicaci√≥n matricial son realmente √∫tiles

# In[42]:


X_o = np.dot(X_1, P_inv)
X_o


# S√≠ es posible recuperar los datos originales.

# Muestra los tres casos para algunos clientes
# 
# - Datos originales
# - El que est√° transformado
# - El que est√° invertido (recuperado)

# In[43]:


print("Datos originales")
print(X[0:5])
print()
print("Datos transformados")
print(X_1[0:5])
print()
print("inversi√≥n de datos transformados")
print(X_o[0:5])


# Seguramente puedes ver que algunos valores no son exactamente iguales a los de los datos originales. ¬øCu√°l podr√≠a ser la raz√≥n de ello?

# Las operaciones decimales.

# In[44]:


pd.options.display.float_format = '{:.2f}'.format
print()
print("Datos originales")
df_X = pd.DataFrame(X[0:5], columns=personal_info_column_list)
print(df_X)
print()
print()
print("Datos transformados")
df_X_1 = pd.DataFrame(X_1[0:5], columns=personal_info_column_list)
print(df_X_1)
print()
print()
print("inversi√≥n de datos transformados")
df_X_o = pd.DataFrame(X_o[0:5], columns=personal_info_column_list)
print(df_X_o)


# Comentarios Tarea 4.
# 
# * Determinaci√≥n de matriz
# * Generaci√≥n de matriz aleatoria
# * Comprobaci√≥n de invertibilidad
# * Obtenci√≥n de Matriz prima
# * Inversi√≥n de Matriz prima

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# En ocasiones los valores se pueden ver ligeramente alterados, sobretodo si son categ√≥ricos. Habr√≠a que hacer una revisi√≥n si es verdad que todos los valores que originalmente eran 0 ahora son negativos. Aunque lo que debes notar es que estos valores aparecen acompa√±ado de un expenente `e-12` o `e-13` lo que quiere decir que es pr√°cticamente 0
# </div>

# ---------------

# ## Prueba de que la ofuscaci√≥n de datos puede funcionar con regresi√≥n lineal

# En este proyecto la tarea de regresi√≥n se ha resuelto con la regresi√≥n lineal. Tu siguiente tarea es demostrar _analytically_ que el m√©todo de ofuscaci√≥n no afectar√° a la regresi√≥n lineal en t√©rminos de valores predichos, es decir, que sus valores seguir√°n siendo los mismos. ¬øLo puedes creer? Pues no hace falta que lo creas, ¬°tienes que que demostrarlo!

# Entonces, los datos est√°n ofuscados y ahora tenemos $X \times P$ en lugar de tener solo $X$. En consecuencia, hay otros pesos $w_P$ como
# 
# $$
# w = (X^T X)^{-1} X^T y \quad \Rightarrow \quad w_P = [(XP)^T XP]^{-1} (XP)^T y
# $$
# 
# ¬øC√≥mo se relacionar√≠an $w$ y $w_P$ si simplific√°ramos la f√≥rmula de $w_P$ anterior?

# **Respuesta**

# Deber√≠an tener el mismo impacto en magnitudes diferentes, ya que $w_P$ se ve afectado por la matriz aleatoria $P$

# ¬øCu√°les ser√≠an los valores predichos con $w_P$? 
# 

# **Respuesta**

# Tendr√≠an un efecto similar a los datos escalados.

# ¬øQu√© significa esto para la calidad de la regresi√≥n lineal si esta se mide mediante la RECM?

# **Respuesta**

# La m√©trica de RECM deber√≠a ser la misma para los datos originales y ofuscados.

# Revisa el Ap√©ndice B Propiedades de las matrices al final del cuaderno. ¬°All√≠ encontrar√°s f√≥rmulas muy √∫tiles!

# 
# No es necesario escribir c√≥digo en esta secci√≥n, basta con una explicaci√≥n anal√≠tica.

# **Prueba anal√≠tica**

# $$
# w_P = I P^{-1} X^{-1} y
# $$

# ----------

# ## Prueba de regresi√≥n lineal con ofuscaci√≥n de datos

# Ahora, probemos que la regresi√≥n lineal pueda funcionar, en t√©rminos computacionales, con la transformaci√≥n de ofuscaci√≥n elegida.
# 
# Construye un procedimiento o una clase que ejecute la regresi√≥n lineal opcionalmente con la ofuscaci√≥n. Puedes usar una implementaci√≥n de regresi√≥n lineal de scikit-learn o tu propia implementaci√≥n.
# 
# Ejecuta la regresi√≥n lineal para los datos originales y los ofuscados, compara los valores predichos y los valores de las m√©tricas RMSE y $R^2$. ¬øHay alguna diferencia?

# **Procedimiento**
# 
# - Crea una matriz cuadrada $P$ de n√∫meros aleatorios.
# - Comprueba que sea invertible. Si no lo es, repite el primer paso hasta obtener una matriz invertible.
# - Se utiliz√≥ la matriz aleatoria previamente generadas.
# - Utiliza $XP$ como la nueva matriz de caracter√≠sticas.

# In[45]:


# Resultados del modelo (pesos, RMSE y R2)

X = df[['gender', 'age', 'income', 'family_members']].to_numpy()
y = df['insurance_benefits'].to_numpy()

X_1_train, X_1_test, y_train, y_test = train_test_split(X_1, y, test_size=0.3, random_state=12345)

lr_o = MyLinearRegression()

lr_o.fit(X_1_train, y_train)
print("Pesos:")
print(lr.weights)

y_test_pred_o = lr_o.predict(X_1_test)
eval_regressor(y_test, y_test_pred_o)


# Comentarios Tarea 5.
# 
# * Resultados del modelo (pesos, RMSE y R2): Las m√©tricas obtenidas en el modelo con datos ofuscados se mantienen en los mismos valores de los datos originales y escalados, los pesos se adaptan a las magnitudes de cada conjunto sin embargo los pesos de los datos ofuscados y los escalados son pr√°cticamente los mismos.
# 
# Datos originales
# 
# Pesos:
# [-9.43539012e-01,  1.64272726e-02,  3.57495491e-02, -2.60743659e-07, -1.16902127e-02]
# 
# RMSE: 0.34
# 
# R2: 0.66
# 
# Datos escalados
# 
# Pesos:
# [-0.94353901,  0.01642727,  2.32372069, -0.02059875, -0.07014128]
# 
# RMSE: 0.34
# 
# R2: 0.66

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (2da Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
#     
# Oscar en esta secci√≥n has realizado el proceso de ofuscaci√≥n de datos de manera correcta. Y vemos como el modelo no se ve afectado con respecto a la prueba con los datos originales. Debes tener en cuenta que ofuscar datos puede ser √∫til para proteger datos personales o corporativos sin perder funcionalidad, pero tiene limitaciones, no es un m√©todo de seguridad completa y no reemplaza al cifrado. Adem√°s, en casos donde los datos necesitan an√°lisis detallados o auditor√≠as completas, la ofuscaci√≥n puede dificultar el proceso, haciendo que no sea adecuada en todos los escenarios.
# 
# </div>

# ----------

# # Conclusiones

# Conclusiones.
# 
# * Se pueden apreciar los efectos que genera el escalado de datos, tambi√©n la ofuscaci√≥n as√≠ como revertir el efecto de la ofuscaci√≥n y comparar los resultados de los pesos y las m√©tricas a manera de saber que se llegan a los mismos resultados en el caso de las m√©tricas.
# 
# * Cabe se√±alar que el enfoque del proyecto no fue necesariamente la mejora de los modelos sino las alternativas al trabajar con matrices.
# 

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class=‚ÄútocSkip‚Äù></a>
# 
# Oscar excelente conclusi√≥n, √©sta refleja una observaci√≥n precisa y bien fundamentada sobre la consistencia de las m√©tricas a pesar de las transformaciones aplicadas a los datos, lo cual demuestra una comprensi√≥n s√≥lida de c√≥mo el escalado y la ofuscaci√≥n afectan principalmente a los coeficientes sin alterar el rendimiento del modelo. Adem√°s, es acertado c√≥mo se√±alas que el objetivo del proyecto no era optimizar el modelo, sino explorar distintas formas de manipular datos manteniendo su integridad.
# 
# Para enriquecer futuros an√°lisis, podr√≠as explorar visualizaciones que evidencien estos efectos en los pesos o bien discutir en qu√© contextos pr√°cticos la ofuscaci√≥n de datos puede ser √∫til, especialmente en entornos donde la privacidad es cr√≠tica.
# </div>

# # Lista de control

# Escribe 'x' para verificar. Luego presiona Shift+Enter.

# - [x]  Jupyter Notebook est√° abierto
# - [ ]  El c√≥digo no tiene errores
# - [ ]  Las celdas est√°n ordenadas de acuerdo con la l√≥gica y el orden de ejecuci√≥n
# - [ ]  Se ha realizado la tarea 1
# - [ ]  Est√° presente el procedimiento que puede devolver k clientes similares para un cliente determinado
# - [ ]  Se prob√≥ el procedimiento para las cuatro combinaciones propuestas    
# - [ ]  Se respondieron las preguntas sobre la escala/distancia
# - [ ]  Se ha realizado la tarea 2
# - [ ]  Se construy√≥ y prob√≥ el modelo de clasificaci√≥n aleatoria para todos los niveles de probabilidad    
# - [ ]  Se construy√≥ y prob√≥ el modelo de clasificaci√≥n kNN tanto para los datos originales como para los escalados. Se calcul√≥ la m√©trica F1.
# - [ ]  Se ha realizado la tarea 3
# - [ ]  Se implement√≥ la soluci√≥n de regresi√≥n lineal mediante operaciones matriciales    
# - [ ]  Se calcul√≥ la RECM para la soluci√≥n implementada
# - [ ]  Se ha realizado la tarea 4
# - [ ]  Se ofuscaron los datos mediante una matriz aleatoria e invertible P    
# - [ ]  Se recuperaron los datos ofuscados y se han mostrado algunos ejemplos    
# - [ ]  Se proporcion√≥ la prueba anal√≠tica de que la transformaci√≥n no afecta a la RECM    
# - [ ]  Se proporcion√≥ la prueba computacional de que la transformaci√≥n no afecta a la RECM
# - [ ]  Se han sacado conclusiones

# # Ap√©ndices
# 
# ## Ap√©ndice A: Escribir f√≥rmulas en los cuadernos de Jupyter

# Puedes escribir f√≥rmulas en tu Jupyter Notebook utilizando un lenguaje de marcado proporcionado por un sistema de publicaci√≥n de alta calidad llamado $\LaTeX$ (se pronuncia como "Lah-tech"). Las f√≥rmulas se ver√°n como las de los libros de texto.
# 
# Para incorporar una f√≥rmula a un texto, pon el signo de d√≥lar (\\$) antes y despu√©s del texto de la f√≥rmula, por ejemplo: $\frac{1}{2} \times \frac{3}{2} = \frac{3}{4}$ or $y = x^2, x \ge 1$.
# 
# Si una f√≥rmula debe estar en el mismo p√°rrafo, pon el doble signo de d√≥lar (\\$\\$) antes y despu√©s del texto de la f√≥rmula, por ejemplo:
# $$
# \bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i.
# $$
# 
# El lenguaje de marcado de [LaTeX](https://es.wikipedia.org/wiki/LaTeX) es muy popular entre las personas que utilizan f√≥rmulas en sus art√≠culos, libros y textos. Puede resultar complicado, pero sus fundamentos son sencillos. Consulta esta [ficha de ayuda](http://tug.ctan.org/info/undergradmath/undergradmath.pdf) (materiales en ingl√©s) de dos p√°ginas para aprender a componer las f√≥rmulas m√°s comunes.

# ## Ap√©ndice B: Propiedades de las matrices

# Las matrices tienen muchas propiedades en cuanto al √°lgebra lineal. Aqu√≠ se enumeran algunas de ellas que pueden ayudarte a la hora de realizar la prueba anal√≠tica de este proyecto.

# <table>
# <tr>
# <td>Distributividad</td><td>$A(B+C)=AB+AC$</td>
# </tr>
# <tr>
# <td>No conmutatividad</td><td>$AB \neq BA$</td>
# </tr>
# <tr>
# <td>Propiedad asociativa de la multiplicaci√≥n</td><td>$(AB)C = A(BC)$</td>
# </tr>
# <tr>
# <td>Propiedad de identidad multiplicativa</td><td>$IA = AI = A$</td>
# </tr>
# <tr>
# <td></td><td>$A^{-1}A = AA^{-1} = I$
# </td>
# </tr>    
# <tr>
# <td></td><td>$(AB)^{-1} = B^{-1}A^{-1}$</td>
# </tr>    
# <tr>
# <td>Reversibilidad de la transposici√≥n de un producto de matrices,</td><td>$(AB)^T = B^TA^T$</td>
# </tr>    
# </table>
